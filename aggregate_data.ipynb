{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "\n",
    "aggregation_interval = 24  \n",
    "data_dir = \"/Users/melisadzanovic/Documents/ML - Thesis/hcs-synthetic-data-generator-main\"\n",
    "json_path = os.path.join(data_dir, \"events_full.json\")\n",
    "\n",
    "def load_data(json_path):\n",
    "    if not os.path.isfile(json_path):\n",
    "        raise FileNotFoundError(f\"File not found: {json_path}\")\n",
    "    with open(json_path) as f:\n",
    "        events = json.load(f)\n",
    "    return pd.DataFrame(events)\n",
    "\n",
    "\n",
    "def create_histogram_data(json_path, aggregation_interval=24):\n",
    "    df = load_data(json_path)\n",
    "\n",
    "    if \"start\" in df.columns and \"timestamp\" in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"start\"].fillna(df[\"timestamp\"]))\n",
    "    elif \"start\" in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"start\"])\n",
    "    elif \"timestamp\" in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    else:\n",
    "        raise ValueError(\"No time column found - need either 'start' or 'timestamp'\")\n",
    "\n",
    "    base_time = df[\"datetime\"].min()\n",
    "    df[\"period\"] = ((df[\"datetime\"] - base_time).dt.total_seconds() //\n",
    "                    (aggregation_interval * 3600)).astype(int)\n",
    "\n",
    "    grouped = df.groupby([\"patient_id\", \"practitioner_id\", \"period\"])\n",
    "    aggregates = []\n",
    "\n",
    "    for (patient_id, practitioner_id, period), group in grouped:\n",
    "        period_start = base_time + pd.Timedelta(hours=aggregation_interval * period)\n",
    "        period_end = period_start + pd.Timedelta(hours=aggregation_interval)\n",
    "\n",
    "        has_appt = (group[\"type\"] == \"Appointment\").any()\n",
    "        has_obs = (group[\"type\"] == \"Observation\").any()\n",
    "        has_enc = (group[\"type\"] == \"Encounter\").any()\n",
    "\n",
    "        has_btg = False\n",
    "        has_care = False\n",
    "        num_btg = 0\n",
    "        num_care = 0\n",
    "        if \"data\" in group.columns:\n",
    "            audit_events = group[group[\"type\"] == \"AuditEvent\"]\n",
    "            if len(audit_events) == 0:\n",
    "                continue\n",
    "            for data in audit_events[\"data\"]:\n",
    "                purpose = data.get(\"purpose\")\n",
    "                if purpose in (\"EMERGENCY\", \"BTG\"):\n",
    "                    has_btg = True\n",
    "                    num_btg += 1\n",
    "                elif purpose == \"CAREMGT\":\n",
    "                    has_care = True\n",
    "                    num_care += 1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if has_appt or has_obs or has_enc or has_btg:\n",
    "            has_care = False\n",
    "            num_care = 0\n",
    "\n",
    "        num_total_events = len(audit_events)\n",
    "        avg_time_between = (audit_events[\"datetime\"].sort_values().diff().dt.total_seconds().mean())\n",
    "        num_unique_resources = audit_events[\"resource\"].nunique() if \"resource\" in audit_events.columns else None\n",
    "\n",
    "        aggregates.append({\n",
    "            \"patient_id\": patient_id,\n",
    "            \"practitioner_id\": practitioner_id,\n",
    "            \"period\": period,\n",
    "            \"period_start\": period_start,\n",
    "            \"period_end\": period_end,\n",
    "            \"has_appointment\": has_appt,\n",
    "            \"has_observation\": has_obs,\n",
    "            \"has_encounter\": has_enc,\n",
    "            \"has_btg_access\": has_btg,\n",
    "            \"has_care_access\": has_care,\n",
    "            \"num_btg_events\": num_btg,\n",
    "            \"num_care_events\": num_care,\n",
    "            \"num_total_events\": num_total_events,\n",
    "            \"avg_time_between_events\": avg_time_between,\n",
    "            \"num_unique_resources_accessed\": num_unique_resources\n",
    "        })\n",
    "\n",
    "    df_out = pd.DataFrame(aggregates)\n",
    "    df_out[\"table_id\"] = df_out.apply(calculate_table_id, axis=1)\n",
    "    df_out[\"label\"] = df_out.apply(determine_label, axis=1)\n",
    "    return df_out\n",
    "\n",
    "def calculate_table_id(row):\n",
    "    a = row[\"has_appointment\"]\n",
    "    o = row[\"has_observation\"]\n",
    "    e = row[\"has_encounter\"]\n",
    "    b = row[\"has_btg_access\"]\n",
    "    return 1 + (int(a)*8 + int(o)*4 + int(e)*2 + int(b)*1)\n",
    "\n",
    "def determine_label(row):\n",
    "    table_id = row[\"table_id\"]\n",
    "    if table_id == 1:\n",
    "        return \"Anomaly\"\n",
    "    return \"Normal\"\n",
    "\n",
    "result_df = create_histogram_data(json_path=json_path, aggregation_interval=aggregation_interval)\n",
    "\n",
    "csv_path = os.path.join(data_dir, f\"labeled_events_full-{aggregation_interval}h.csv\")\n",
    "result_df.to_csv(csv_path, index=False)\n",
    "print(f\"CSV saved: {csv_path}\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(result_df[\"label\"].value_counts())\n",
    "print(\"\\n=== Table ID ===\")\n",
    "print(result_df[\"table_id\"].value_counts().sort_index())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (amlfall 3.9.6)",
   "language": "python",
   "name": "amlfall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
